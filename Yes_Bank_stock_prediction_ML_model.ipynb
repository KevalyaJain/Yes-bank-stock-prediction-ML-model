{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "FJNUwmbgGyua",
        "mDgbUHAGgjLW",
        "-Kee-DAl2viO",
        "gIfDvo9L0UH2"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Name**    -\n",
        "\n"
      ],
      "metadata": {
        "id": "vncDsAP0Gaoa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Project Type**    - EDA/Regression (Yes Bank Stock Prediction Model)\n",
        "##### **Contribution**    - Individual\n",
        "##### **Team Member 1 -** Kevalya jain\n"
      ],
      "metadata": {
        "id": "beRrZCGUAJYm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Summary -**"
      ],
      "metadata": {
        "id": "FJNUwmbgGyua"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yes Bank is a well-known bank in the Indian financial domain which provides wide range of services and solutions right from bank accounts,deposits, cards, cash management, privilege banking and many more. As the data is all about stock price. So in this project i will be analyzing the patterns of the dataset by performing exploratary data analysis and try to build a machine learning model for predicting the closing stock price. The tools for data analysis and model building used in this project are the packages from python library such as NumPy, Pands, Matplotlib, Seaborn, Linear regression, Lasso, Lasso Cross Validation, Ridge, Ridge Cross validation etc."
      ],
      "metadata": {
        "id": "F6v_1wHtG2nS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **GitHub Link -**"
      ],
      "metadata": {
        "id": "w6K7xa23Elo4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Provide your GitHub Link here."
      ],
      "metadata": {
        "id": "h1o69JH3Eqqn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Problem Statement**\n"
      ],
      "metadata": {
        "id": "yQaldy8SH6Dl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " Yes Bank is a well-known bank in the Indian financial domain. Since 2018, it has been in the news because of the fraud case involving Rana Kapoor. Owing to this fact, it was interesting to see how that impacted the stock prices of the company and whether Time series models or any other predictive models can do justice to such situations. This dataset has monthly stock prices of the bank since its inception and includes closing, starting, highest, and lowest stock prices of every month. The main objective is to predict the stockâ€™s closing price of the month."
      ],
      "metadata": {
        "id": "DpeJGUA3kjGy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **General Guidelines** : -  "
      ],
      "metadata": {
        "id": "mDgbUHAGgjLW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.   Well-structured, formatted, and commented code is required.\n",
        "2.   Exception Handling, Production Grade Code & Deployment Ready Code will be a plus. Those students will be awarded some additional credits.\n",
        "     \n",
        "     The additional credits will have advantages over other students during Star Student selection.\n",
        "       \n",
        "             [ Note: - Deployment Ready Code is defined as, the whole .ipynb notebook should be executable in one go\n",
        "                       without a single error logged. ]\n",
        "\n",
        "3.   Each and every logic should have proper comments.\n",
        "4. You may add as many number of charts you want. Make Sure for each and every chart the following format should be answered.\n",
        "        \n",
        "\n",
        "```\n",
        "# Chart visualization code\n",
        "```\n",
        "            \n",
        "\n",
        "*   Why did you pick the specific chart?\n",
        "*   What is/are the insight(s) found from the chart?\n",
        "* Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason.\n",
        "\n",
        "5. You have to create at least 15 logical & meaningful charts having important insights.\n",
        "\n",
        "\n",
        "[ Hints : - Do the Vizualization in  a structured way while following \"UBM\" Rule.\n",
        "\n",
        "U - Univariate Analysis,\n",
        "\n",
        "B - Bivariate Analysis (Numerical - Categorical, Numerical - Numerical, Categorical - Categorical)\n",
        "\n",
        "M - Multivariate Analysis\n",
        " ]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "6. You may add more ml algorithms for model creation. Make sure for each and every algorithm, the following format should be answered.\n",
        "\n",
        "\n",
        "*   Explain the ML Model used and it's performance using Evaluation metric Score Chart.\n",
        "\n",
        "\n",
        "*   Cross- Validation & Hyperparameter Tuning\n",
        "\n",
        "*   Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart.\n",
        "\n",
        "*   Explain each evaluation metric's indication towards business and the business impact pf the ML model used.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ZrxVaUj-hHfC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Let's Begin !***"
      ],
      "metadata": {
        "id": "O_i_v8NEhb9l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***1. Know Your Data***"
      ],
      "metadata": {
        "id": "HhfV-JJviCcP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import Libraries"
      ],
      "metadata": {
        "id": "Y3lxredqlCYt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from datetime import datetime\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.linear_model import Lasso\n",
        "from sklearn.linear_model import LassoCV\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.linear_model import RidgeCV\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn import metrics"
      ],
      "metadata": {
        "id": "M8Vqi-pPk-HR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Loading"
      ],
      "metadata": {
        "id": "3RnN4peoiCZX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Dataset\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "df= pd.read_csv(\"/content/drive/MyDrive/data_YesBank_StockPrices.csv\")"
      ],
      "metadata": {
        "id": "4CkvbW_SlZ_R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset First View"
      ],
      "metadata": {
        "id": "x71ZqKXriCWQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset First Look\n",
        "df.head()"
      ],
      "metadata": {
        "id": "LWNFOSvLl09H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.tail()"
      ],
      "metadata": {
        "id": "SEBSE2zhiqo_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Rows & Columns count"
      ],
      "metadata": {
        "id": "7hBIi_osiCS2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Rows & Columns count\n",
        "df.shape"
      ],
      "metadata": {
        "id": "Kllu7SJgmLij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Information"
      ],
      "metadata": {
        "id": "JlHwYmJAmNHm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Info\n",
        "print(df.info())\n",
        "df['Date'] = pd.to_datetime(df['Date'].apply(lambda x: datetime.strptime(x,'%b-%y')))\n",
        "print(df.info())"
      ],
      "metadata": {
        "id": "e9hRXRi6meOf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Duplicate Values"
      ],
      "metadata": {
        "id": "35m5QtbWiB9F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Duplicate Value Count\n",
        "df.duplicated().sum()"
      ],
      "metadata": {
        "id": "1sLdpKYkmox0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Missing Values/Null Values"
      ],
      "metadata": {
        "id": "PoPl-ycgm1ru"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Missing Values/Null Values Count\n",
        "df.isnull().sum()\n"
      ],
      "metadata": {
        "id": "GgHWkxvamxVg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What did you know about your dataset?"
      ],
      "metadata": {
        "id": "H0kj-8xxnORC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This Data set has no missing values and no duplicated values all columns are numerical columns and date column has been changed to datetime date type."
      ],
      "metadata": {
        "id": "gfoNAAC-nUe_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***2. Understanding Your Variables***"
      ],
      "metadata": {
        "id": "nA9Y7ga8ng1Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Columns\n",
        "df.columns"
      ],
      "metadata": {
        "id": "j7xfkqrt5Ag5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Describe\n",
        "df.describe(include='all')"
      ],
      "metadata": {
        "id": "DnOaZdaE5Q5t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Variables Description"
      ],
      "metadata": {
        "id": "PBTbrJXOngz2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We have 5 Columns\n",
        "\n",
        "Date:- It contains 1st day of every month from year 2005\n",
        "\n",
        "Open:- The open prices of yes bank Stock on that particular date\n",
        "\n",
        "High:- The Highest price it reached on that day\n",
        "\n",
        "Low:- The lowest price it reached on that day\n",
        "\n",
        "close:- The Closing price of Yes bank stock on that particular date (Target Variable)"
      ],
      "metadata": {
        "id": "qWnJqBw0YBbf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can clearly see that our mean and much higher than our median in every feature so this distribution must be right skewed."
      ],
      "metadata": {
        "id": "aJV4KIxSnxay"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Check Unique Values for each variable."
      ],
      "metadata": {
        "id": "u3PMJOP6ngxN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check Unique Values for each variable.\n",
        "df.nunique()"
      ],
      "metadata": {
        "id": "zms12Yq5n-jE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***4. Data Vizualization, Storytelling & Experimenting with charts : Understand the relationships between variables***"
      ],
      "metadata": {
        "id": "GF8Ens_Soomf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 1"
      ],
      "metadata": {
        "id": "0wOQAZs5pc--"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 1 visualization code\n",
        "col= df.columns.drop('Date')\n",
        "print(col)\n",
        "for i in col:\n",
        "  plt.figure(figsize=(12,4))\n",
        "  sns.lineplot(data=df, x=df['Date'], y=df[i])\n",
        "  plt.title(i)"
      ],
      "metadata": {
        "id": "7v_ESjsspbW7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "K5QZ13OEpz2H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This line chart shows us the trend for our all features ie Open, Close, High, Low with respect to date"
      ],
      "metadata": {
        "id": "XESiWehPqBRc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "lQ7QKXXCp7Bj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "There is no seasonality in trend and also the share price has a massive drop in year 2018-2020 because of the scam or fraud done in Yes bank"
      ],
      "metadata": {
        "id": "C_j1G7yiqdRP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "448CDAPjqfQr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The bussiness was in good trend and have performed good till 2018 but after scam it has been just came down to where it started."
      ],
      "metadata": {
        "id": "3cspy4FjqxJW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 2"
      ],
      "metadata": {
        "id": "KSlN3yHqYklG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 2 visualization code\n",
        "for i in col:\n",
        "  plt.figure(figsize=(12,4))\n",
        "  sns.distplot(df[i])\n",
        "  plt.title(i)"
      ],
      "metadata": {
        "id": "R4YgtaqtYklH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "t6dVpIINYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This distplot is used to check the skewness of our features"
      ],
      "metadata": {
        "id": "5aaW0BYyYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "ijmpgYnKYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The data is right skewed for all the features"
      ],
      "metadata": {
        "id": "PSx9atu2YklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "-JiQyfWJYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yes we found that our data is right skewed."
      ],
      "metadata": {
        "id": "BcBbebzrYklV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 3"
      ],
      "metadata": {
        "id": "EM7whBJCYoAo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 3 visualization code\n",
        "for i in col:\n",
        "  plt.figure(figsize=(12,4))\n",
        "  sns.distplot(np.log10(df[i]))\n",
        "  plt.title(i)\n"
      ],
      "metadata": {
        "id": "t6GMdE67YoAp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "fge-S5ZAYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We used a log10 transformation to transform our data in normal distribution"
      ],
      "metadata": {
        "id": "5dBItgRVYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 4"
      ],
      "metadata": {
        "id": "OH-pJp9IphqM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 6 visualization code\n",
        "df['Year'] = pd.to_datetime(df['Date'], format='%b-%y').dt.year\n",
        "plt.figure(figsize=(14,6))\n",
        "avg_close = df.groupby(['Year'])['Close'].mean().reset_index()\n",
        "ax= sns.barplot(data=df,x=df['Year'],y=df['Close'],ci=None)\n",
        "for i in ax.containers:\n",
        "  ax.bar_label(i,fmt='%.0f')"
      ],
      "metadata": {
        "id": "kuRf4wtuphqN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "bbFf2-_FphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this Bar chart we created a new column of Year and we used group by funtion to find the average Close price for each year from 2005-2020 and showed it in the bar graph format."
      ],
      "metadata": {
        "id": "loh7H2nzphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "_ouA3fa0phqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "There was a rise in close price value for 2017 but in 2019 the value got decreased due to fraud in Yes bank"
      ],
      "metadata": {
        "id": "VECbqPI7phqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "Seke61FWphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This can give us the knowledge or we can research on the strategy which yes bank opted by which there stock prices has increased in year 2016-2018."
      ],
      "metadata": {
        "id": "DW4_bGpfphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 5"
      ],
      "metadata": {
        "id": "PIIx-8_IphqN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 7 visualization code\n",
        "df['monthly_change_percentage'] = round((abs(df['Close'].shift(+1)-df['Close'])/df['Close'].shift(+1))*100, 3)\n",
        "sns.histplot(df['monthly_change_percentage'], bins=20, kde=True)"
      ],
      "metadata": {
        "id": "lqAIGUfyphqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "t27r6nlMphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This histogram is used to show the count that how many time the average monthly change in closing price has been distributed for which we have created a new feature which has the monthly change % for closing price."
      ],
      "metadata": {
        "id": "iv6ro40sphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "r2jJGEOYphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Most of the times the monthly percentage change varies in 0-10% but we also saw that there is changes more than 50% in a month that can be in 2019-2020"
      ],
      "metadata": {
        "id": "Po6ZPi4hphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "b0JNsNcRphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yes this insights gave us the knowledge that the stock was consitant and has low volatility or less monthly change %."
      ],
      "metadata": {
        "id": "xvSq8iUTphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 6"
      ],
      "metadata": {
        "id": "BZR9WyysphqO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 8 visualization code\n",
        "plt.figure(figsize=(14,6))\n",
        "sns.lineplot(data=df,x=df['Date'],y=df['monthly_change_percentage'])\n",
        "plt.title('Monthly change percentage in closing price(%)')"
      ],
      "metadata": {
        "id": "TdPTWpAVphqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "jj7wYXLtphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This line chart is used to check wheather this is any seasonality pattern in monhtly change percentage"
      ],
      "metadata": {
        "id": "Ob8u6rCTphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "eZrbJ2SmphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "No we didnt found any good insights from it"
      ],
      "metadata": {
        "id": "mZtgC_hjphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "rFu4xreNphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "NA"
      ],
      "metadata": {
        "id": "ey_0qi68phqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 7 - Correlation Heatmap"
      ],
      "metadata": {
        "id": "NC_X3p0fY2L0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Correlation Heatmap visualization code\n",
        "corr=df.corr()\n",
        "sns.heatmap(corr,annot=True , square=True)"
      ],
      "metadata": {
        "id": "xyC9zolEZNRQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "UV0SzAkaZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This Heat map shows us the correlation between our features"
      ],
      "metadata": {
        "id": "DVPuT8LYZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "YPEH6qLeZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "All our features are highly co-related to each other"
      ],
      "metadata": {
        "id": "P3qs1rJOVqlk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 8 - multi-colinearity"
      ],
      "metadata": {
        "id": "q29F0dvdveiT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Pair Plot visualization code\n",
        "for i in col.drop('Close'):\n",
        "  fig = plt.figure(figsize = (12,4))\n",
        "  features = df[i]\n",
        "  label = df['Close']\n",
        "  plt.scatter(x = features,y = label)\n",
        "  plt.xlabel(i)\n",
        "  plt.title(i)\n",
        "  plt.ylabel('Close')"
      ],
      "metadata": {
        "id": "o58-TEIhveiU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "EXh0U9oCveiU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "These scatter plot are used to check the colinearity between the features with our target feature"
      ],
      "metadata": {
        "id": "eMmPjTByveiU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "22aHeOlLveiV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "# This is formatted as code\n",
        "```\n",
        "\n",
        "All our features are directly proportianal to our target feature ie if our value of target feature will increase the value of our other features will also increase."
      ],
      "metadata": {
        "id": "uPQ8RGwHveiV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***6. Feature Engineering & Data Pre-processing***"
      ],
      "metadata": {
        "id": "yLjJCtPM0KBk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Handling Missing Values"
      ],
      "metadata": {
        "id": "xiyOF9F70UgQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Data Transformation\n",
        "print(df.info())\n",
        "df = df.drop('Year',axis=1)\n",
        "df.set_index('Date', inplace= True)\n",
        "print(df.info())\n",
        "print(df.isnull().sum())"
      ],
      "metadata": {
        "id": "iRsAHk1K0fpS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here We dropped our extracted year feature which we used for our EDA also we set our Date column as index and then we found that there are no missing values except one null value in our newly created feature and we will keep that value as it is."
      ],
      "metadata": {
        "id": "1ixusLtI0pqI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Handling Outliers"
      ],
      "metadata": {
        "id": "id1riN9m0vUs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling Outliers & Outlier treatments\n",
        "print(\"Actual Data\")\n",
        "for i in col:\n",
        "  plt.figure(figsize=(12,4))\n",
        "  plt.boxplot(df[i])\n",
        "  plt.title(i)"
      ],
      "metadata": {
        "id": "M6w2CzZf04JK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see that we have lot many of outlier and also we saw that our data is right skewed so the best approach to handle right skewed data and treat outliers can be Log transformation"
      ],
      "metadata": {
        "id": "awS4XesZYSpe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "col1= df.columns\n",
        "col1\n",
        "df_transformed= np.log10(df[col1])\n",
        "for i in col1.drop('monthly_change_percentage'):\n",
        "  plt.figure(figsize=(12,4))\n",
        "  plt.boxplot(df_transformed[i])\n",
        "  plt.title(i)"
      ],
      "metadata": {
        "id": "oRWShR_7YhaJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What all outlier treatment techniques have you used and why did you use those techniques?"
      ],
      "metadata": {
        "id": "578E2V7j08f6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "So by using log transformation we removed our outliers and also we made our data as uniform distributed data"
      ],
      "metadata": {
        "id": "uGZz5OrT1HH-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5. Data Transformation"
      ],
      "metadata": {
        "id": "TNVZ9zx19K6k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Do you think that your data needs to be transformed? If yes, which transformation have you used. Explain Why?"
      ],
      "metadata": {
        "id": "nqoHp30x9hH9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We have already transformed our data using log10 transformation above."
      ],
      "metadata": {
        "id": "qDXti4TahvnS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Transform Your data\n",
        "df_transformed['monthly_change_percentage'].fillna(0.03, inplace=True)"
      ],
      "metadata": {
        "id": "I6quWQ1T9rtH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we have only one null value so we imputted this value as 0.03"
      ],
      "metadata": {
        "id": "oe-IaOBmgw0k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 8. Data Splitting"
      ],
      "metadata": {
        "id": "BhH2vgX9EjGr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Scaling your data\n",
        "X= df_transformed.drop(columns=['Close'])\n",
        "y= df_transformed['Close']\n",
        "X_train, X_test, y_train, y_test= train_test_split(X, y , test_size=0.30, random_state=42)"
      ],
      "metadata": {
        "id": "dL9LWpySC6x_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What data splitting ratio have you used and why?"
      ],
      "metadata": {
        "id": "qjKvONjwE8ra"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We have splitted our training data as 70% and testing data 30% because we have very less amount of data"
      ],
      "metadata": {
        "id": "Y2lJ8cobFDb_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6. Data Scaling"
      ],
      "metadata": {
        "id": "rMDnDkt2B6du"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split your data to train and test. Choose Splitting ratio wisely.\n",
        "scaler =  MinMaxScaler()\n",
        "X_train= scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "0CTyd2UwEyNM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which method have you used to scale you data and why?"
      ],
      "metadata": {
        "id": "yiiVWRdJDDil"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We have used Min Max Scaling to bring our data on same scale."
      ],
      "metadata": {
        "id": "xpmjIx29pdQY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***7. ML Model Implementation***"
      ],
      "metadata": {
        "id": "VfCC591jGiD4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 1"
      ],
      "metadata": {
        "id": "OB4l2ZhMeS1U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 1 Implementation\n",
        "model = LinearRegression()\n",
        "# Fit the Algorithm\n",
        "reg_model= model.fit(X_train,y_train)\n",
        "# Predict on the model\n",
        "y_predict_train= model.predict(X_train)\n"
      ],
      "metadata": {
        "id": "7ebyywQieS1U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "ArJBuiUVfxKd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart\n",
        "# Test Performance\n",
        "print(\"Model Score:\", model.score(X_train,y_train))\n",
        "print(\"MSE :\",mean_squared_error(y_test, y_predict_test))\n",
        "print(\"RMSE :\",math.sqrt(mean_squared_error(y_test, y_predict_test)))\n",
        "print(\"MAE :\",mean_absolute_error(y_test, y_predict_test))\n",
        "print(\"R2 :\",r2_score(y_test, y_predict_test))"
      ],
      "metadata": {
        "id": "rqD5ZohzfxKe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train Performance\n",
        "print(\"MSE :\",mean_squared_error(y_train, y_predict_train))\n",
        "print(\"RMSE :\",math.sqrt(mean_squared_error(y_train, y_predict_train)))\n",
        "print(\"MAE :\",mean_absolute_error(y_train, y_predict_train))\n",
        "print(\"R2 :\",r2_score(y_train, y_predict_train))"
      ],
      "metadata": {
        "id": "_6VAGQIMYgvm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plotting Actual vs predicted values on line chart."
      ],
      "metadata": {
        "id": "AlZ9uJ-DWm9q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(10**y_predict_test)\n",
        "plt.plot(np.array(10**(y_test)))\n",
        "plt.legend(['Predicted','Actual'])\n",
        "plt.title(\"Actual values vs predicted value\")"
      ],
      "metadata": {
        "id": "9jWN7HBXWksj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 2"
      ],
      "metadata": {
        "id": "dJ2tPlVmpsJ0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 2 Implementation\n",
        "lasso = Lasso(alpha=0.1)\n",
        "# Fit the Algorithm\n",
        "lasso_model = lasso.fit(X_train,y_train)\n",
        "# Predict on the model\n",
        "y_lasso_predict= lasso.predict(X_test)"
      ],
      "metadata": {
        "id": "4LOVbbJxWyQc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "JWYfwnehpsJ1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Test Performance\n",
        "print(\"Score:\", lasso.score(X_train,y_train))\n",
        "print(\"MSE :\",mean_squared_error(y_test, y_lasso_predict))\n",
        "print(\"RMSE :\",math.sqrt(mean_squared_error(y_test, y_lasso_predict)))\n",
        "print(\"MAE :\",mean_absolute_error(y_test, y_lasso_predict))\n",
        "print(\"R2 :\",r2_score(y_test, y_lasso_predict))"
      ],
      "metadata": {
        "id": "E53mVrcdSapU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(10**y_lasso_predict)\n",
        "plt.plot(np.array(10**y_test))\n",
        "plt.legend(['Predicted','Actual'])\n",
        "plt.title(\"Actual values vs predicted value\")"
      ],
      "metadata": {
        "id": "YbSdmD9-TcGV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "-jK_YjpMpsJ2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 1 Implementation with hyperparameter optimization techniques (i.e., GridSearch CV, RandomSearch CV, Bayesian Optimization etc.)\n",
        "alphas= [0.0001,0.001,0.01,0.1,1.0,10.0,100.0]\n",
        "lasso_cv= LassoCV(alphas=alphas, cv=5)\n",
        "# Fit the Algorithm\n",
        "lasso_cv.fit(X_train,y_train)\n",
        "#Best alpha value\n",
        "best_alpha = lasso_cv.alpha_\n",
        "print(\"Best Alpha:\", best_alpha)\n",
        "# Predict on the model\n",
        "y_pred_lasso= lasso_cv.predict(X_test)"
      ],
      "metadata": {
        "id": "Dn0EOfS6psJ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "bkPW5fuVXHrn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Test Performance\n",
        "print(\"Score:\", lasso_cv.score(X_train,y_train))\n",
        "print(\"MSE :\",mean_squared_error(y_test, y_pred_lasso))\n",
        "print(\"RMSE :\",math.sqrt(mean_squared_error(y_test, y_pred_lasso)))\n",
        "print(\"MAE :\",mean_absolute_error(y_test, y_pred_lasso))\n",
        "print(\"R2 :\",r2_score(y_test, y_pred_lasso))"
      ],
      "metadata": {
        "id": "h1ozEsiRXPbI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(10**y_pred_lasso)\n",
        "plt.plot(np.array(10**y_test))\n",
        "plt.legend(['Predicted','Actual'])\n",
        "plt.title(\"Actual values vs predicted value\")"
      ],
      "metadata": {
        "id": "LsIpv2wsWTrQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ],
      "metadata": {
        "id": "HAih1iBOpsJ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I used Lasso Cross Validation for optimization technique with the best alpha value of 0.0001"
      ],
      "metadata": {
        "id": "9kBgjYcdpsJ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "zVGeBEFhpsJ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we have very limited data and our model can train on this data in the best way so we dont have any more improvement in it its already giving the best accuracy for training and testing data also there is no issues of Overfitting or underfitting problem"
      ],
      "metadata": {
        "id": "74yRdG6UpsJ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3. Explain each evaluation metric's indication towards business and the business impact pf the ML model used."
      ],
      "metadata": {
        "id": "bmKjuQ-FpsJ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "R2 is already very close to 1 that shows our model is best."
      ],
      "metadata": {
        "id": "BDKtOrBQpsJ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 3"
      ],
      "metadata": {
        "id": "Fze-IPXLpx6K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 2 Implementation\n",
        "ridge = Ridge(alpha=0.1)\n",
        "# Fit the Algorithm\n",
        "ridge_model = ridge.fit(X_train,y_train)\n",
        "# Predict on the model\n",
        "y_ridge_predict= ridge.predict(X_test)"
      ],
      "metadata": {
        "id": "FFrSXAtrpx6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "7AN1z2sKpx6M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Test Performance\n",
        "print(\"Score:\", ridge.score(X_train,y_train))\n",
        "print(\"MSE :\",mean_squared_error(y_test, y_ridge_predict))\n",
        "print(\"RMSE :\",math.sqrt(mean_squared_error(y_test, y_ridge_predict)))\n",
        "print(\"MAE :\",mean_absolute_error(y_test, y_ridge_predict))\n",
        "print(\"R2 :\",r2_score(y_test, y_ridge_predict))"
      ],
      "metadata": {
        "id": "xIY4lxxGpx6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(10**y_ridge_predict)\n",
        "plt.plot(np.array(10**y_test))\n",
        "plt.legend(['Predicted','Actual'])\n",
        "plt.title(\"Actual values vs predicted value\")"
      ],
      "metadata": {
        "id": "IBVzXdNHZqXi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "9PIHJqyupx6M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 1 Implementation with hyperparameter optimization techniques (i.e., GridSearch CV, RandomSearch CV, Bayesian Optimization etc.)\n",
        "alphas= [0.0001,0.001,0.01,0.1,1.0,10.0,100.0]\n",
        "ridge_cv= RidgeCV(alphas=alphas, cv=5)\n",
        "# Fit the Algorithm\n",
        "ridge_cv.fit(X_train,y_train)\n",
        "#Best alpha value\n",
        "best_alpha_1 = ridge_cv.alpha_\n",
        "print(\"Best Alpha:\", best_alpha)\n",
        "# Predict on the model\n",
        "y_pred_ridge= ridge_cv.predict(X_test)"
      ],
      "metadata": {
        "id": "eSVXuaSKpx6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Score:\", ridge_cv.score(X_train,y_train))\n",
        "print(\"MSE :\",mean_squared_error(y_test, y_pred_ridge))\n",
        "print(\"RMSE :\",math.sqrt(mean_squared_error(y_test, y_pred_ridge)))\n",
        "print(\"MAE :\",mean_absolute_error(y_test, y_pred_ridge))\n",
        "print(\"R2 :\",r2_score(y_test, y_pred_ridge))"
      ],
      "metadata": {
        "id": "RS9h-943a-hU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(10**y_pred_ridge)\n",
        "plt.plot(np.array(10**y_test))\n",
        "plt.legend(['Predicted','Actual'])\n",
        "plt.title(\"Actual values vs predicted value\")"
      ],
      "metadata": {
        "id": "cSuAVMl9a_Cy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ],
      "metadata": {
        "id": "_-qAgymDpx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I used Ridge Cross Validation for optimization technique with the best alpha value of 0.0001"
      ],
      "metadata": {
        "id": "lQMffxkwpx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "Z-hykwinpx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we have very limited data and our model can train on this data in the best way so we dont have any more improvement in it its already giving the best accuracy for training and testing data also there is no issues of Overfitting or underfitting problem"
      ],
      "metadata": {
        "id": "MzVzZC6opx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Which ML model did you choose from the above created models as your final prediction model and why?"
      ],
      "metadata": {
        "id": "cBFFvTBNJzUa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We dont have any difference in accuracy or evalution matrics for any of the above 3 models so ill choose simple linear regression model as my best model for this particular data for our predictions."
      ],
      "metadata": {
        "id": "6ksF5Q1LKTVm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Congrats! Your model is successfully created and ready for deployment on a live server for a real user interaction !!!***"
      ],
      "metadata": {
        "id": "-Kee-DAl2viO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Conclusion**"
      ],
      "metadata": {
        "id": "gCX9965dhzqZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yes bank stock prediction\n",
        "\n",
        "We load our data using Pandas\n",
        "\n",
        "we saw that our data in right skewed with the help of distplot\n",
        "\n",
        "then we saw the trends of our each features\n",
        "\n",
        "after that we have created a new feature that tells us about the monthly change\n",
        "\n",
        "percentage on the basis of our close price\n",
        "\n",
        "then we visualized average closing price of each year\n",
        "\n",
        "and we saw the histogram and trend of the new column\n",
        "\n",
        "and visualized our outliers using box plot\n",
        "\n",
        "then we got that our data need to be in uniform distribution so we applied log10 transformation on our data and set date column as index\n",
        "\n",
        "we have only one missing value in new created column which was filled by 0.03\n",
        "value\n",
        "\n",
        "we split or data into 70-30 ratio of train and test\n",
        "\n",
        "now using Min Max Scaler we scaled our data\n",
        "\n",
        "and now we started our ML modelling\n",
        "\n",
        "we used Linear regression and evaluated its MSE RMSE MAE and R2 values and got best results\n",
        "\n",
        "then we used Lasso model and did Lasso Cross Validation with best alpha hyperparameter as 0.0001 and again we got almost same matrices\n",
        "\n",
        "and finally we used Ridge regression model and Ridge Cross Validation with best alpha hyperparameter as 0.0001 and got the same results\n",
        "\n",
        "as our data is so limited and we dont have prices on per day basis so we can not perform time series analysis on the model so we will go with simple linear regression model as our best model for this regression prediction model."
      ],
      "metadata": {
        "id": "Fjb1IsQkh3yE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Hurrah! You have successfully completed your Machine Learning Capstone Project !!!***"
      ],
      "metadata": {
        "id": "gIfDvo9L0UH2"
      }
    }
  ]
}
